---
title : 텐서플로우, 케라스 개념 정리
toc : true
toc_sticky : true
---


## PART2 TENSORFLOW
**텐서플로우의 기능 : 자동 미분 (automatic differentiation)**  

(1) create dataset  
	first, create dataset with ‘generator’ ( tf.random 모듈 )  
    * 정규분포를 갖는 10개의 숫자 데이터 -> 변수 x에 저장  
    * 선형 함수식을 만족하는 값을 대입 -> 변수 y에 저장  

> (참고)  
> ‘딥러닝 모델 학습’ 한 줄 요약 :  
> 모델의 예측 값 & 실제 값의 차이를 최소화하는 모델의 계수, 상수항을 찾는 과정  
> 여기서 ‘차이’ : loss  

ex_MSE(평균 제곱 오차)를 계산하는 손실함수를 정의해보자
```python
Def cal_mse (X, Y, a, b):
	y_pred = a * X + b
	squared_error = (y_pred - Y) ** 2
	mean_squared_error = tf.reduce_mean(sqaure_error)
	
	return mean_squared_error
```


- - - -

< 어떻게 학습이 이루어지는가 >   
1. 모델의 계수와 상수항에 해당하는 변수 a, b를 생성한다 <— 초기값은 둘 다 0.0  
2. 몇 번 돌릴지 설정 : 200에포크. 
3. With 구문 안에서 일어나는 일
* cal_mse 함수로 계산한 결과는 mse 변수에 저장  
* Gradient 함수 사용하여 얻어진 미분값 —> grad 변수에 저장 (계수 a : g_a, 상수항 b : g_b)  
* 미분값에 학습률 0.05를 적용하여 곱함 —> 기존 계수, 상수항에서 차감
* 차감된 값을 다음 에포크의 입력값으로 사용
4. A, b 값을 계속 업데이트 함(mse를 낮추는 방향으로)
5. 결과 : mse는 0에 가까워지고 실제 값에 근사하는 것을 확인 가능

예제 코드 : 
```python
#tf.GradientTape로 자동 미분 과정을 기록한다.

a = tf.Variable(0,0)
b = tf.Variable(0,0)

EPOCHS = 200

for epoch in range(1, EPOCHS + 1):
	with tf.GradientTape() as tape :
		mse = cal_mse(X, Y, a, b)
	
	grad = tape.gradient(mse, {‘a’:a, ‘b’:b})
	d_a, d_b = grad[‘a’], grad[‘b’]

	a.assign_sub(d_a * 0.05)
	b.assign_sub(d_b * 0.05)
	
	if epoch % 20 == 0 :
		print(“EPOCH %d - MSE: %.4f —— a: %.2f —— b: %.2f” %(epoch, mse, a, b))
```

- - - -

## PART3 KERAS
* 텐서플로우2가 1과 가장 다른 점 : 케라스 내장  
* 케라스 api : 고수준 딥러닝 라이브러리  
* 케라스의 특장점 :  
gpu 연산 수행 기능을 직접 돌리지 않고 백엔드 엔진을 지정하여 사용한다는 것 (텐서플로우 위에 만들어진 케라스)  
* 케라스의 목적 : 딥러닝 라이브러리를 쉽고 간결한 코드로 실행할 수 있도록 하는 것.


**주요 용어**
* 하이퍼 파라미터(hyper-parameter)  
-ML 모델 훈련 시 사용자가 직접 설정해주는 설정값 (ex 학습 속도, 반복 훈련 횟수 등)  
-사용자가 별도 설정하지 않으면 기본값이 자동으로 적용된다  
-모델의 예측 성능을 높이는 데 관여하는 키포인트들 (a.k.a 하이퍼파라미터 튜닝)     

* 과소적합 & 과대적합  
배경지식 : ML 학습에 쓰이는 데이터는 두 종류  
	(1) 훈련용 train set : ML 모델이 학습할 데이터  
	(2) 예측용 test set : ML 모델이 예측해야 하는 대상 데이터, 정답 레이블이 없다  
		- 훈련 데이터에서 패턴 학습을 진행 -> 모델이 완성됨  
		- 반복 학습의 효과 : 사람이 못찾는 패턴을 발견 -> 예측 성능이 좋은 모델 생성 
	- 과소적합 : 모델이 충분히 학습되지 않아 예측 성능이 떨어진 상태
	- 과대적합 : 학습 데이터를 지나치게 학습해서 그 결과가 과하게 적합된 상태
 
    
🐦 **가장 베스트 결과를 만들려면**  
과소적합, 과대적합 문제를 최소화 & 정확도를 최대한 높이기  
훈련 데이터 잘 구성하기 ( 훈련 데이터 예측 데이터 분포 동일하게 맞추기, 데이터 분석 전처리로 노이즈 없애기, 검증 성능이 가장 좋은 구간을 기준으로 최종 모델 결정하기 )

* 에포크  
에포크 = 1회 훈련 루프 (반복 훈련 시 훈련 데이터셋이 모두 1번 모델 훈련에 사용되는 것)

* 손실함수 : 예측 값, 정답 값의 차이 / 오차

* 지도학습  
	(1) 이진 분류
    * 손실함수 : binary-crossentropy / 활성화 함수 : sigmoid  

	(2) 다중 분류  
    * 손실함수 : categorical_crossentropy (다중 분류 대상 클래스가 원핫 벡터인 경우 사용)  
    * 손실함수 : sparse_categorical_crossentropy (레이블 값이 다른 숫자로 구분 된 경우 사용)  
    * 활성화 함수 : softmax


**경사하강법**  
딥러닝 모델 훈련 시, 모델 내부 가중치에 대한 미분 값을 구하고 목적 함수 값이 낮아지는 방향으로 차감 ➜ 최소 함수 값을 갖게 하는 방법  
🚨 중요!  최적화 함수(옵티마이저)의 근간이 되는 알고리즘

1. 손실함수(Loss Function) 정의  
단순 선형회귀 수식의 계수(w)와 상수(b)를 구할 때 사용한다.  
“계수와 상수 설정 기준 = 손실함수가 최소가 될 때”  
2. 샘플 데이터셋 생성 함수 정의, 임의의 w, b 값 지정  
w, b 값을 왜 지정하는가? 주어진 x에 대한 y값 생성  
참고) y값 생성 시 약간의 노이즈도 추가  

```python
import numpy as np
import matplotlib.pyploy as plt

#샘플 데이터셋
def make_linear(w=0.5, b=0.5, size=50, noise=1.0):
    x = np.random.rand(size)
    y = w * x + b
    noise = np.random.uniform(-abs(npose), abs(noise), size = y.shape)
    yy = y + noise
    plt.figure(figsize=(10,7))
    plt.plot(x, y, color = 'r', label = f'y = {w} * x + b')
    plt.scatter(x, yy, label = 'data')
    plt.legend(fontsize = 20)
    plt.show()
    print(f'w: {w}, b: {b}')
    return x, yy

x, y = make_linear(w = 0.3, b = 0.5, size = 100, noise = 0.01)
```

3. w, b에 대한 그래디언트 구하기  
그래디언트 : 각 변수의 기울기에 해당 
에포크 횟수만큼 반복하는 동안 손실함수에 w, b값을 변화해서 적용한다.(가중치 업데이트)  
어떻게? w, b에 대한 각각의 편미분 값 * 학습률 계수 ➜ 이전 w, b 값으로부터 차감  

```python
num_epoch = 1000 #최대 반복 횟수
learning_rate = 0.005 #학습률
errors = []    #to record errors

#initialize w, b with random number between 0~1
w = np.random.uniform(low = 0.0, high = 1.0)
b = np.random.uniform(low = 0.0, high = 1.0)

for epoch in range(num_epoch):
    # define hypothesis
    y_hat = w * x + b
    
    # define loss function
    error = 0.5 * ((y_hat - y) **2).sum()
    if error < 0.005:
        break
    #calculating gradient (differentiation)
    w = w - learning_rate * ((y_hat - y) * x).sum()
    b = b - learning_rate * (y_hat - y).sum()
    
    errors.append(error)

    if epoch % 5 == 0:
        print("{0:2} w = {1:.5f}, b = {2:.5f} error = {3:.5f}".format(epoch, w, b, error))

print("----" * 15)
print("{0:2} w = {1:.1f}, b = {2:.1f} error = {3:.5f}".format(epoch, w, b, error))
```

4. 결과 확인  
반복을 통해 가중치가 설정되게 됨.    
반복을 종료한 w, b 계수 : 샘플 데이터셋 생성시 설장한 w, b 값에 근접함을 알 수 있다.  

```python
plt.figure(figsize = (10, 7))
plt.plot(errors)
plt.xlabel('Epochs')
plt.ylabel('Error')
plt.show()
```
