---
title : "[TensorFlow] 코랩을 이용한 강아지/고양이 분류"
excerpt : "[part 04 합성곱 신경망(CNN) 05 개/고양이 이미지 분류]에 대한 내용 정리"

toc : true
toc_sticky : true

categories :
  - Tensorflow

tags :
  - tensorflow
  - kaggle


header :
  teaser : "/assets/images/teaser3.png"
---

> "part 04 합성곱 신경망(CNN) 05 개/고양이 이미지 분류"에 대한 내용 정리  
> "교재에서 제공하는 코드는 [여기](https://github.com/yoooniverse/tf-practice)에 전체 받아적어 두었다.

앞선 포스팅에서는 모델에 넣을 데이터를 케라스 / 텐서플로우 데이터셋을 통해 확보했다. 하지만 실제 업무에서 다루는 데이터는 파일 형태로, 라이브러리에서 자체 제공하는 데이터셋과는 차이가 있다.  

그리고, 지금까지 다뤘던 데이터보다 훨씬 규모가 크기 때문에 고성능 GPU를 갖춘 작업환경에서 데이터셋을 다루는 작업을 진행하는 경우가 많다.
실무에서 다루는 이미지 파일이 용량이 크거나 개수가 많으면 컴퓨터 메모리 / 그래픽 카드 메모리가 부족한 상황도 많이 발생한다.

이러한 문제에 대한 해결 방안으로 이용되는 것이 '배치(batch)' 개념이다.  
이미지 데이터셋을 32장, 64장, 128장 등 일정 단위(배치 단위)로 나눈 후, 배치 1개씩을 읽어와서 딥러닝 모델에 적용하는 것이다. 이러한 학습 방식은 컴퓨터의 메모리 부담을 줄여준다는 장점을 지닌다. 전체 데이터셋을 모델에 주입할때까지 배치 단위로 데이터를 읽어오는 것이다.

해당 파트에서는 데이터셋을 배치 단위로 분리하는 방법과, 반복 객체를 이용해 각 배치를 모델에 주입하는 방법에 대하여 배운다.  
이 과정에서 도움을 주는 텐서플로우 케라스 함수인 `ImageDataGenerator` 함수를 이용한다.


### 1. 분석 준비
#### 1.1 데이터셋 다운로드
데이터 : 캐글에 공개된 'Cat and Dog' 데이터셋을 이용한다. [자료출처](https://www.kaggle.com/tongpython/cat-and-dog)  
로컬 pc에 다운로드 → 구글 코랩 실행 → 구글 드라이브에 마운트하여 데이터를 준비  
구글 드라이브 [내 드라이브]에 'dataset' 폴더 생성 → 해당 폴더에 'cat-and-dog.zip' 파일 업로드  

#### 1.2 라이브러리 불러오기
필요한 라이브러리 : 텐서플로우, 넘파이, matplotlib, 케라스 ImageDataGenerator 함수
```python
import tensorflow as tf
from tensorflow.keras.preprocessing.image import ImageDataGenerator

import numpy as np
import matplotlib.pylab as plt
```

#### 1.3 구글 드라이브 마운트
구글 코랩을 사용하기 때문에 구글 드라이브 폴더를 마운트해준다.
```python
from google.colab import drive
drive.mount("/content/drive")
```

#### 1.4 압축 파일 해제
drive_path : 압축 파일 위치 저장 변수  
source_filename : 파일 경로 지정 변수  
extract_folder : 해제된 파일을 저장할 변수 <- 코랩 실행 환경에 임시 저장한다. 구글 드라이브에 저장하는 것보다 파일 로딩 시간이 훨씬 단축된다.
```python
# 압축파일 위치
drive_path = "/content/drive/MyDrive/"
source_filename = drive_path + "dataset/cat-and-dog.zip"

# 데이터셋 저장할 경로
extract_folder = "dataset/"

# 압축 해제
import shutil
shutil.unpack_archive(source_filename, extract_folder)
```
훈련 셋, 검증 셋을 저장할 위치를 지정한다. 각자 훈련 데이터, 검증 데이터 폴더 안으로 들어가도록 구성한다.


### 2. 모델 학습
#### 2.1 ImageDataGenerator
ImageDataGenerator 클래스 함수를 실행하여 이미지 픽셀 값을 정규화한다. 생성된 제너레이터 객체는 image_gen 변수에 할당한다.
```python
image_gen = ImageDataGenerator(rescale=(1/255.))
image_gen
```
#### 2.2 flow_from_directory 함수
flow_from_directory 함수의 역할 : 지정 폴더에서 이미지를 가져와 반복 이터레이션이 가능하도록 데이터셋을 처리한다.
함수에서 지정하는 것들
- train_dir : 훈련셋 저장 위치
- batch_size : 배치 1개에 들어갈 이미지 개수
- target_size : 이미지 사이즈
- classes : 클래스 레이블 (여기서는 이미지가 들어있는 하위 폴더 이름이 이에 해당)
- class_mode : 이진 분류 문제임을 표기
- seed : 랜덤 시드 값

```python
train_gen = image_gen.flow_from_directory(train_dir,
                                          target_size=(224, 224),
                                          classes=['cats', 'dogs'],
                                          class_mode='binary',
                                          batch_size=32,
                                          seed=2020,)

valid_gen = image_gen.flow_from_directory(valid_dir,
                                          target_size=(224, 224),
                                          classes=['cats', 'dogs'],
                                          class_mode='binary',
                                          batch_size=32,
                                          seed=2020,)
```

#### 2.3 모델 훈련
이진 분류 모델의 구성 : '배치 정규화 - 합성곱 - 풀링' 단위블럭 * 3
최종 분류기 : Dense 레이어 (출력 레이어 노드 : 1개, 활성화 함수 : sigmoid)

샘플 모델 생성
```python
#Sequential API를 이용해 샘플 모델 생성

def build_model():

  model = tf.keras.Sequential([
    
    #convolution 층
    tf.keras.layers.BatchNormalization(),
    tf.keras.layers.Conv2D(32, (3,3), padding='same', activation='relu'),
    tf.keras.layers.MaxPooling2D((2,2)),

    tf.keras.layers.BatchNormalization(),
    tf.keras.layers.Conv2D(64, (3,3), padding='same', activation='relu'),
    tf.keras.layers.MaxPooling2D((2,2)),

    tf.keras.layers.BatchNormalization(),
    tf.keras.layers.Conv2D(128, (3,3), padding='same', activation='relu'),
    tf.keras.layers.MaxPooling2D((2,2)),

    #classifier 출력층
    tf.keras.layers.Flatten(),
    tf.keras.layers.Dense(256, activation='relu'),
    tf.keras.layers.Dropout(0.5),
    tf.keras.layers.Dense(1, activation='sigmoid'),
  ])

  return model

model = build_model()
```

```python
#옵티마이저, 손실함수 지정
#epoch : 20

#모델 컴파일
model.compile(optimizer=tf.optimizers.Adam(lr=0.001),
              loss=tf.keras.losses.BinaryCrossentropy(from_logits=True),
              metrics=['accuracy'])

#모델 훈련
history = model.fit(train_gen, validation_data=valid_gen, epochs=20)
```

![손실 함수 그래프](/assets/images/output4.png) 

모델 훈련 후 손실 함수 그래프를 그리면 과대적합이 빠르게 발생했음을 확인할 수 있다. (주어진 훈련 셋에는 높은 정확도, 검증 셋에는 낮은 정확도) 기존 데이터의 규칙에 과하게 적응하여 새로운 데이터의 규칙을 잘 예측하지 못하는 것.

#### 2.4 데이터 증강(Augmentation)
ImageDataGenerator 함수를 이용해 데이터 증강 기법을 쉽게 적용할 수 있다.(클래스 함수의 매개변수 속성으로)  
추가할 속성 : 좌우 방향 전환, 30도 회전, 이미지 반시계 방향으로 밀리도록 변형, 이미지 확대

데이터에 어떻게 증강 기법을 적용할 것인가? 이미지를 배치 크기 단위로 불러와 증강 기법을 적용한 미니 배치를 구성한다. 이것들을 모아서 반복 이터레이션 객체를 만든다.
```python
image_gen_aug = ImageDataGenerator(rescale=1/255.,
                                   horizontal_flip=True,
                                   rotation_range=30,
                                   shear_range=0.15,
                                   zoom_range=0.3)

train_gen_aug = image_gen_aug.flow_from_directory(train_dir,
                                                  batch_size=32,
                                                  target_size=(224, 224),
                                                  classes=['cats','dogs'],
                                                  class_mode='binary',
                                                  seed=2020)

valid_gen_aug = image_gen_aug.flow_from_directory(valid_dir,
                                                  batch_size=32,
                                                  target_size=(224, 224),
                                                  classes=['cats','dogs'],
                                                  class_mode='binary',
                                                  seed=2020)

model_aug = build_model()

model_aug.compile(optimizer=tf.optimizers.Adam(lr=0.001),
              loss=tf.keras.losses.BinaryCrossentropy(from_logits=True),
              metrics=['accuracy'])

history_aug = model_aug.fit(train_gen_aug, validation_data=valid_gen_aug, epochs=40)
```
![손실 함수 그래프](/assets/images/output5.png)  
검증셋 그래프를 확인하면 증강 기법을 적용하기 전 20 epoch까지 돌린 모델보다 더 높은 수준의 정확도를 보인다. 85% 수준까지 높아졌으므로 epoch 횟수를 더 늘리면 정확도 가 더 높아질 가능성이 존재한다.