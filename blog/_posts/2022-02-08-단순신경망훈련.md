---
title : ë‹¨ìˆœ ì‹ ê²½ë§ í›ˆë ¨
toc : true
toc_sticky : true
---


> *"part 3 ì¼€ë¼ìŠ¤(Keras) 02 ë‹¨ìˆœ ì‹ ê²½ë§ í›ˆë ¨"ì— ëŒ€í•œ ì •ë¦¬*

## 2.1 ì„ í˜•íšŒê·€
**- íšŒê·€ë¶„ì„** : ë…ë¦½ë³€ìˆ˜(í•˜ë‚˜ ì´ìƒ) âœ ì¢…ì†ë³€ìˆ˜ì— ë¯¸ì¹˜ëŠ” ì˜í–¥ì„ ì¶”ì •í•˜ëŠ” í†µê³„ ê¸°ë²•  

**- ë‹¨ìˆœì„ í˜•íšŒê·€(simple linear regression)** : í•˜ë‚˜ì˜ Xê°€ Yì— ë¯¸ì¹˜ëŠ” ì˜í–¥ì„ ì¶”ì • (1ì°¨ í•¨ìˆ˜ ê´€ê³„ y = ax + b)

** <í…ì„œí”Œë¡œìš° ì¼€ë¼ìŠ¤ë¥¼ í™œìš©í•´ êµ¬í˜„í•œ ë‹¨ìˆœì…˜í˜•íšŒê·€ ëª¨ë¸> **  
ë‹¨ìˆœì„ í˜•íšŒê·€ ëª¨ë¸ë¡œ í•™ìŠµí•˜ëŠ” ê³¼ì •  
: ëª¨ë¸ì˜ ê¸°ìš¸ê¸° aì™€ ì ˆí¸ bë¥¼ ì—…ë°ì´íŠ¸í•˜ë©´ì„œ ì¢…ì†ë³€ìˆ˜ yì— ê°€ì¥ ê·¼ì‚¬í•œ 1ì°¨ í•¨ìˆ˜ì‹ì„ ì™„ì„±ì‹œí‚¨ë‹¤. (ê¸°ìš¸ê¸° a ëŒ€ì‹  ê°€ì¤‘ì¹˜ë¥¼ ì˜ë¯¸í•˜ëŠ” wë¥¼ ë” ë§ì´ ì‚¬ìš©)  
**ğŸš¨ y = wx + b**


---


## 2.2 ë‰´ëŸ°
**- ë‰´ëŸ°** : ì¸ê³µ ì‹ ê²½ë§ ëª¨ë¸ì„ êµ¬ì„±í•˜ëŠ” í•˜ë‚˜ì˜ ì‹ ê²½ (a.k.a ë…¸ë“œ)  

**- ì‹ ê²½ë§** : ì—¬ëŸ¬ ê°œì˜ ë ˆì´ì–´ë¡œ êµ¬ì„±, 1ê°œì˜ ë ˆì´ì–´ëŠ” 1ê°œ ì´ìƒì˜ ë‰´ëŸ°ìœ¼ë¡œ êµ¬ì„±  

- ë‰´ëŸ°ì˜ ë‚´ë¶€ì— ê°€ì¤‘ì¹˜ê°€ ì¡´ì¬  
- ëª¨ë¸ì´ í›ˆë ¨ì„ ì§„í–‰í•˜ë©° ë‰´ëŸ°ì˜ ê°€ì¤‘ì¹˜ê°€ ì—…ë°ì´íŠ¸ ëœë‹¤. (ì˜¤ì°¨ ì—­ì „íŒŒ ì´ìš©)


> **- ì—­ì „ì°¨ ì•Œê³ ë¦¬ì¦˜ (back propagation algorithm)**  
> : ì‹ ê²½ë§ ëª¨ë¸ì˜ íŒŒë¼ë¯¸í„°ë“¤ì— ëŒ€í•œ ê·¸ë˜ë””ì–¸íŠ¸ë¥¼ ê³„ì‚°í•˜ëŠ” ë°©ë²•  
> 
> **- ê·¸ë˜ë””ì–¸íŠ¸**  
> : ê° ë ˆì´ì–´ì™€ ê´€ë ¨ëœ ì†ì‹¤í•¨ìˆ˜ë¥¼ ë¯¸ë¶„í•œ ê²°ê³¼
>  
> **point) ê·¸ë˜ë””ì–¸íŠ¸ë¥¼ ì¶œë ¥ì¸µì—ì„œ ì…ë ¥ì¸µ ë°©í–¥ìœ¼ë¡œ ì—­ìœ¼ë¡œ ê³„ì‚°**

---

## 2.3 Dense ë ˆì´ì–´
**- Dense ë ˆì´ì–´** : ì‹¬ì¸µ ì‹ ê²½ë§ ëª¨ë¸ì„ êµ¬ì„±í•˜ëŠ” ê°€ì¥ ê¸°ë³¸ ë ˆì´ì–´  
a.k.a "ì™„ì „ ì—°ê²°ì¸µ(Fully Connected Layer)" : ê° ë ˆì´ì–´ ì‚¬ì´ì˜ ëª¨ë“  ë‰´ëŸ°ì´ ì„œë¡œ ì—°ê²°ë˜ì–´ ìˆê¸° ë•Œë¬¸  

4ê°œì˜ Dense ë ˆì´ì–´ ì˜ˆì‹œ  
![ì™„ì „ ì—°ê²°ì¸µ](/assets/images/layer_example.png)  
input layer 1 + hidden layer 2 + output layer 1  
input layer : 3 neurons  
hidden layer : 4 neurons each  
output layer : 1 neuron  
âœ ëª¨ë“  ë‰´ëŸ°ë“¤ì´ ì •ë³´(í…ì„œ)ì˜ íë¦„ì„ ë‚˜íƒ€ë‚´ëŠ” í™”ì‚´í‘œë¡œ ì—°ê²°ëœë‹¤. (ì™„ì „ì—°ê²°ì¸µì´ë¼ê³  ë¶€ë¥´ëŠ” ì´ìœ )  

ì‹¤ì œ ì½”ë“œë¡œ êµ¬í˜„í•  ìˆ˜ ìˆë‹¤.  
```python
import tensorflow as tf

tf.keras.layers.Dense(10) #10ê°œì˜ ë…¸ë“œë¡œ ì´ë£¨ì–´ì§„ Dense ë ˆì´ì–´
tf.keras.laters.Dense(10, activation = 'relu') #í™œì„±í™” í•¨ìˆ˜ : ReLU
```
---

## 2.4 ë°ì´í„°ì…‹ ë§Œë“¤ê¸°
ë°ì´í„°ì…‹ì˜ í•„ìš”ì„± : ì§€ë„í•™ìŠµ ë°©ì‹ìœ¼ë¡œ í›ˆë ¨í•˜ê¸° ìœ„í•´  

**ìƒ˜í”Œ ë°ì´í„°ì…‹ì„ ë§Œë“¤ì–´ë³´ì**  
ìƒì„± ê³¼ì • : x ë°ì´í„° 5ê°œ ìƒì„± â†’ ì„ì˜ì˜ 1ì°¨ í•¨ìˆ˜ y = 3x + 2 ê´€ê³„ì‹ì— ëŒ€ì… â†’ y ë°ì´í„° 5ê°œ ìƒì„±  
```python
x = np.arange(1, 6) #ìƒ˜í”Œ ë°ì´í„°ì…‹ ìƒì„±
y = 3 * x + 2 # y = 3x + 2

print(x)
print(y)
```

<br>ìƒì„±í•œ ë°ì´í„° í™•ì¸ : matplotlib ë¼ì´ë¸ŒëŸ¬ë¦¬ë¥¼ ì‚¬ìš©í•´ ê·¸ë˜í”„ ì¶œë ¥  
```python
import matplotlib.pyplot as plt

plt.plot(x, y)
plt.title('y = 3x + 2')
plt.show()
```
---
## 2.5 Sequential API
**- Sequential APIë€?** í…ì„œí”Œë¡œìš° ì¼€ë¼ìŠ¤ì˜ ëª¨ë¸ ìƒì„± ë°©ì‹ 3ê°€ì§€ ì¤‘ í•˜ë‚˜.  
**- ì–´ë–¤ ë°©ì‹?** ì‹œí€€ìŠ¤ì— ë§ê²Œ ì¼ë ¬ë¡œ ì—°ê²°í•˜ëŠ” ë°©ì‹  
(the order exists between input layer & output layer)  

âœ ì…ë ¥ ë°ì´í„°ëŠ” input layerë¡œ ë“¤ì–´ê°€ì„œ ì‚¬ì´ì˜ layerë“¤ì„ ìˆœì„œëŒ€ë¡œ í†µê³¼, ë”¥ëŸ¬ë‹ ì—°ì‚° ìˆ˜í–‰  

**pros** : ì§ê´€ì  êµ¬ì¡°, ì¼€ë¼ìŠ¤ ëª¨ë¸ ìƒì„± í›ˆë ¨ì„ í•  ìˆ˜ ìˆëŠ” simplest API  
**cons** : ë³µì¡í•œ êµ¬ì¡°ë¥¼ ë§Œë“¤ ìˆ˜ ì—†ìŒ (ex_2ê°œ ì´ìƒì˜ ë‹¤ì¤‘ ì…ë ¥, ë‹¤ì¤‘ ì¶œë ¥ì„ ê°–ëŠ” êµ¬ì¡°)

### 2.5.1 ëª¨ë¸ êµ¬ì¡°
sequential APIë¡œ ëª¨ë¸ì„ ë§Œë“œëŠ” ë°©ë²•  

ë°©ë²• 1) ë¦¬ìŠ¤íŠ¸í˜• ì •ì˜  
```python
import tensorflow as tf

model = tf.keras.Sequential([
    tf.keras.layers.Dense(10),
    tf.keras.layers.Dense(5),
    tf.keras.layers.Dense(1),
])
```

<br>ë°©ë²• 2) add í•¨ìˆ˜ë¡œ ë ˆì´ì–´ ì¶”ê°€  
(1) add í•¨ìˆ˜ë¡œ Sequential í´ë˜ìŠ¤ ê°ì²´ë¥¼ ë¨¼ì € ìƒì„±  
(2) ìƒì„±ëœ ëª¨ë¸ ì¸ìŠ¤í„´ìŠ¤ì— ë ˆì´ì–´ë¥¼ ì¶”ê°€  
```python
model = tf.keras.Sequential()

model.add(tf.keras.layers.Dense(10))
model.add(tf.keras.layers.Dense(5))
model.add(tf.keras.layers.Dense(1))
```

ì°¸ê³ ) Sequential APIë¡œ ë§Œë“¤ ìˆ˜ ìˆëŠ” ë ˆì´ì–´ì˜ ìˆ˜ëŠ” ì œí•œ ì—†ìŒ

### 2.5.2 ì…ë ¥ ë°ì´í„° í˜•íƒœ
Sequential API ì‚¬ìš©ì‹œ : input layerì˜ **input_shape ë§¤ê°œë³€ìˆ˜ í•„ìˆ˜ë¡œ ì§€ì •**  

example) ë°ì´í„°ì…‹ì˜ shapeì´ (150, 4)ë¡œ êµ¬ì„±ë˜ì—ˆì„ ê²½ìš°  
ì˜ë¯¸) 150ê°œ ìƒ˜í”Œì— ëŒ€í•´ 4ê°œì˜ ì…ë ¥ ë³€ìˆ˜ê°€ ì¡´ì¬
```python
inport tensorflow as tf
model = tf.keras.Sequential([
    tf.keras.layers.Dense(10, input_shape=[4]),
    tf.keras.layers.Dense(5),
    tf.keras.layers.Dense(1),
])
```

### 2.5.3 ë‹¨ìˆœì„ í˜•íšŒê·€ ëª¨ë¸ ì •ì˜
**ë‹¨ìˆœì„ í˜•íšŒê·€ ëª¨ë¸** : Dense ë ˆì´ì–´ 1ê°œ ì‚¬ìš© ( ë‰´ëŸ° : 1ê°œ )  
â†’ ë‰´ëŸ° : w, bë¥¼ ë§¤ê°œë³€ìˆ˜ë¡œ ê°€ì§  

1ì°¨ í•¨ìˆ˜ì‹ **y = wx + b**  
ì…ë ¥ ë³€ìˆ˜ 1ê°œ(x), ì¶œë ¥ ë³€ìˆ˜ 1ê°œ(yì˜ ì˜ˆì¸¡ê°’)
```python
model = tf.keras.Sequential([
    tf.keras.laters.Dense(1, input_shape=[1])
])
```
ì°¸ê³ )  
Dense ë ˆì´ì–´ì˜ ê¸°ë³¸ ì„¤ì • : use_bias = True  
ë”°ë¼ì„œ ìƒìˆ˜í•­ bê°€ ë³„ë„ ì ˆì°¨ ì—†ì´ ì¶”ê°€ëœë‹¤.  
ìƒìˆ˜í•­ bë¥¼ í¬í•¨í•˜ì§€ ì•Šìœ¼ë ¤ë©´ use_bias = False

---

## 2.6 ëª¨ë¸ ìš”ì•½
`model.summary()` : ëª¨ë¸ ìš”ì•½ í™•ì¸  
í™•ì¸ ê°€ëŠ¥í•œ ì •ë³´  
- ëª¨ë¸ì˜ êµ¬ì¡°
- ì¸µë³„ ë…¸ë“œì˜ ê°œìˆ˜
- í›ˆë ¨ì‹œ ì—…ë°ì´íŠ¸í•  íŒŒë¼ë¯¸í„° ê°œìˆ˜
  - Total params : ëª¨ë“  íŒŒë¼ë¯¸í„° í•©ê³„
  - Trainable params : ì—…ë°ì´íŠ¸í•  íŒŒë¼ë¯¸í„° ì´ ê°œìˆ˜
  - Non-trainable params : ì—…ë°ì´íŠ¸ í•˜ì§€ ì•Šì„ íŒŒë¼ë¯¸í„° ê°œìˆ˜

---

## 2.7 ì»´íŒŒì¼
ì˜µí‹°ë§ˆì´ì €(optimizer) / ì†ì‹¤í•¨ìˆ˜(loss funtion) / í‰ê°€ì§€í‘œ(metrics) ì •ì˜ ë‹¨ê³„

ì§€ì • ë°©ë²• : 3ê°€ì§€  
1. í´ë˜ìŠ¤ ì¸ìŠ¤í„´ìŠ¤ : í•˜ì´í¼íŒŒë¼ë¯¸í„° ì§ì ‘ ì§€ì • ê°€ëŠ¥
2. ë¬¸ìì—´ : í•˜ì´í¼íŒŒë¼ë¯¸í„°ëŠ” ë¯¸ë¦¬ ì„¤ì •ëœ ê¸°ë³¸ê°’ìœ¼ë¡œ ì ìš© (ìˆ˜ì • ì–´ë ¤ì›€)
3. í•¨ìˆ˜

```python
#ê¸´ ë¬¸ìì—´ ver.
model.compile(optimizer='sgd', loss='mean_squared_error', metrics='[mean_squared_error', 'mean_absolute_error'])

#ì§§ì€ ë¬¸ìì—´ ver.
model.compile(optimizer='sgd', loss='mse', metrics=['mse', 'mae'])

#í´ë˜ìŠ¤ ì¸ìŠ¤í„´ìŠ¤
model.compile(optimizer=tf.keras.optimizers.SGD(lr=0.005), loss=tf.keras.losses.MeanAbsolutionError(), mertrics=[tf.keras.metrics.MeanAbsoluteError(), tf.keras.metrics.ManSquaredError()])
```
-SGD : ì˜µí‹°ë§ˆì´ì € / í™•ë¥ ì  ê²½ì‚¬í•˜ê°•ë²•(Stochastic Gradient Descent)  
-mse : ì†ì‹¤í•¨ìˆ˜ / í‰ê· ì œê³±ì˜¤ì°¨(Mean Squared Error)  
-mae : í‰ê°€ì§€í‘œ / í‰ê· ì ˆëŒ€ì˜¤ì°¨(Mean Absolute Error)

ì»´íŒŒì¼ í•˜ê¸° :  
`model.compile(optimizer='sgd', loss='mse', metrics=['mae'])`

---

## 2.8 í›ˆë ¨
`model.fit(x, y, epoch=5)`

**- í›ˆë ¨ ì‹œì‘í•˜ë ¤ë©´?** ëª¨ë¸ ì¸ìŠ¤í„´ìŠ¤ì— fit() ë©”ì†Œë“œ ì ìš©  

**- í›ˆë ¨** == ê°€ì¤‘ì¹˜ í…ì„œ ì—…ë°ì´íŠ¸ ê³¼ì •  

**- ì—í¬í¬** == ë°˜ë³µ í›ˆë ¨ ìˆ˜  
- ì—í¬í¬ê°€ ëë‚  ë•Œë§ˆë‹¤ í›ˆë ¨ ë°ì´í„°ì…‹ì— ëŒ€í•œ ì†ì‹¤, í‰ê°€ì§€í‘œ ì¶œë ¥  
  - ê²€ì¦ ë°ì´í„°ì…‹(validation_data) ì˜µì…˜ì„ ì§€ì •í•œ ê²½ìš°
- ì¶œë ¥ì„ ì›í•˜ì§€ ì•ŠëŠ”ë‹¤ë©´ : `verbose = 0` ì„ ë„£ì–´ì£¼ì

<br>ì‹¤ì œ ì½”ë“œ ì˜ˆì‹œ
```python
#ë‹¨ìˆœ ì„ í˜•íšŒê·€ ëª¨ë¸ ìƒì„±
model = tf.keras.Sequential([
    tf.keras.laters.Dense(1, input_shape=[1])
])

#ì»´íŒŒì¼
model.compile(optimizer='sgd', loss='mse', metrics=['mae'])

#í›ˆë ¨
#epochë³„ í›ˆë ¨ ì†Œì‹¤, í‰ê°€ì§€í‘œê°€ ë”•ì…”ë„ˆë¦¬ í˜•íƒœë¡œ ì €ì¥ë¨
history = model.fit(x, y, epochs=1200)
```

<br>history ë³€ìˆ˜ë¥¼ ì´ì–´ì„œ ì‚¬ìš©í•˜ì—¬ epochë³„ í›ˆë ¨ ì†ì‹¤ ë° í‰ê°€ì§€í‘œë¥¼ ì‹œê°í™”í•˜ì
```python
import matplotlib.pyplot as plt

plt.plot(history.history['loss'], label='loss')
plt.plot(history.history['mae'], label='mae')
plt.xlim(-1, 20)
plt.title('Loss')
plt.legend()
plt.show()
```

---

## 2.9 ê²€ì¦
**ëª¨ë¸ ì¸ìŠ¤í„´ìŠ¤ì˜ evaluate() ë©”ì†Œë“œë¥¼ ì‚¬ìš©í•œë‹¤.**  
ê²€ì¦ ë°ì´í„°ì…‹ì„ ì…ë ¥í•˜ì—¬ í•´ë‹¹ ëª¨ë¸ì„ ê²€ì¦

`model.evaluate(x, y)`
~~(ì±…ì—ì„œëŠ” ë”°ë¡œ ë§Œë“¤ì–´ë‘” ê²€ì¦ ë°ì´í„°ì…‹ì´ ì—†ì–´ì„œ x, y ë°ì´í„°ë¥¼ ë‹¤ì‹œ ê²€ì¦ì— ì‚¬ìš©í–ˆë‹¤)~~

**êµì°¨ ê²€ì¦** : ë³„ë„ì˜ ë°ì´í„°ì…‹ìœ¼ë¡œ ëª¨ë¸ ì„±ëŠ¥ì„ í‰ê°€í•˜ëŠ” ë°©ë²•  
- Hold-out, K-Fold ë“±ë“±ë“±...

---

## 2.10 ì˜ˆì¸¡
**ëª¨ë¸ ì¸ìŠ¤í„´ìŠ¤ì˜ predict() ë©”ì†Œë“œë¥¼ ì‚¬ìš©í•œë‹¤.**  
í•´ë‹¹ ë©”ì†Œë“œì— ìƒˆë¡œìš´ ì…ë ¥ ë°ì´í„°ë¥¼ ë„£ì–´ì£¼ê¸°

`model.predict([10])` â† xë¥¼ ë©”ì†Œë“œì˜ ì¸ìë¡œ ì§€ì •. ë¦¬ìŠ¤íŠ¸ í˜•íƒœë¡œ ì…ë ¥
