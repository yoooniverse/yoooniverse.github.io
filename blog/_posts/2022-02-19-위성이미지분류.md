---
title : "[TensorFlow] EuroSAT 데이터셋 이미지 분류"

toc : true
toc_sticky : true

categories : 
  - Tensorflow

tags :
  - tensorflow
  - data augmentation
  - resnet50v2

header :
  teaser : "/assets/images/teaser2.png"
---

> "part 04 합성곱 신경망(CNN) 04 위성 이미지 분류"에 대한 내용 정리  


> "교재에서 제공하는 코드는 [여기](https://github.com/yoooniverse/tf-practice)에 전체 받아적어 두었다.

**EuroSAT 데이터셋** : 인공위성에서 지표면을 촬영한 이미지와 토지이용분류 값이 정리되어 있는 데이터셋

**구성** : 27,000장의 위성 사진과 10개의 토지이용분류 값이 매칭되어 제공된다.

### **1. 데이터셋 로드**
데이터셋을 불러와야 한다.  
필요한 라이브러리들을 불러오고(tensorflow_datasets, tensorflow, numpy 등등...)
EuroSAT 데이터셋을 load 함수로 불러온다. 불러온 데이터의 반환된 형태를 보면 '(훈련셋, 검증셋), 메타정보' 이렇게 정리되어 있음을 알 수 있다.

메타 정보는 info 변수에 저장된다. `with_info=True` 옵션을 설정해주어야 불러오는게 가능하다.  
'dataset'이라는 폴더에 데이터를 불러와 저장시키도록 저장 경로를 지정한다. 데이터는 train 데이터만 제공하기 때문에 우리가 자체적으로 8:2 분리해서 훈련셋, 검증셋으로 나누어야 한다.
이미지의 형태는 (64, 64, 3) 형태를 가진다. rgb라서 채널 3개, 이미지 크기가 64*64 픽셀임을 알 수 있다.

```python
DATA_DIR = "dataset/"

(train_ds, valid_ds).info = tfds.load('eurosat/rgb', split=['train[:80%]', 'train[80%:]'],
                                     shuffle_files=True,
                                     as_supervised=True,
                                     with_info=True,
                                     data_dir=DATA_DIR)

print(train_ds)
print(valid_ds)
```

info 변수를 불러와서 학인하면 데이터셋에 대한 기본 정보를 확인할 수 있다. `print(info)`
대충 요약하자면 JPEG로 인코딩된 27,000장 데이터셋이 있고 RGB 데이터셋이라고 말해주는 중임. 클래스는 10개로 나뉘어있다는 것도 알수 있다.

샘플 이미지를 분류 레이블과 함께 출력해서 확인할 수도 있다. 표 형식으로도 볼 수 있다.

```python
tfds.show_examples(train_ds, info)

#as_dataframe 사용해서 샘플 출력
tfds.as_dataframe(valid_ds.take(10), info)
```

클래스의 개수를 확인하거나, 각 클래스가 어떤 문자열 레이블에 해당하는지 변환도 해볼 수 있다.
```python
NUM_CLASSES = info.features["label"].num_classes
print(NUM_CLASSES)

#숫자 레이블을 활용해 문제열 메타 데이터로 변환한다.
#클래스 6 : 영구작물(Permanent Crop)을 의미
print(info.features["label"].int2str(6))
```

### **2. 데이터 전처리**
텐서플로우 데이터셋의 장점 중 하나가 다른 데이터셋들에 비해 전처리가 쉽다는 점이다. 물론 데이터셋을 쉽게 구할 수 있다는 것도 장점이다.  
데이터 전처리에 필요한 함수들, 텐서 연산을 효율적으로 처리할 수 있는 최적화 기능을 제공한다.

**prepocess_data 함수** : 데이터의 자료형을 float32로 변환하고, 이미지의 픽셀 값을 정규화해주는 함수를 먼저 적용해준다.

- 텐서플로우 연산은 float32 숫자 값을 사용하기 때문에 형변환을 한 번 해줘야 한다. (cast 함수 사용)
- 입력 이미지의 픽셀 값은 0~255 사이의 값을 가진다. 이 값들을 255로 나눠서 정규화 해준다.

**map 함수** : 
- 사용자 정의 함수를 매핑하여 텐서플로우 데이터셋에 적용하는 메소드. 자세한 설명은 [이 블로그](https://blockdmask.tistory.com/531)와 [텐서플로우 페이지](https://www.tensorflow.org/guide/data_performance)를 보고 이해했다.
- "num_parallel_calls" 옵션을 AUTOTUNE으로 지정하면 텐서플로우의 병렬연산 처리가 자동으로 최적화된다.  
(이해한 바를 요약해보자면,, map 함수는 매핑을 일대일로 순서대로 진행하는데 이를 더 빨리 처리하기 위해 num paraller calls 옵션을 지정해주면 여러 샘플에 병렬적으로 매핑이 진행될 수 있다)

정규화 변환을 완료한 데이터셋에 shuffle() 메소드를 적용해서 순서를 랜덤하게 섞는다.
suffle은 입력 순서에 무작위성을 부여해서 모델의 성능을 높일 수 있다.

- buffer size = 1000 : 1000개의 데이터를 가져와 섞는다
- batch size = 64 : 가져온 데이터 중 64개를 랜덤하게 선택해서 하나의 배치로 구성한다.
- 추출되어 빈자리가 된 64개의 데이터 자리는 다른 데이터가 해당 버퍼에 들어와서 1000개를 유지하도록 구성된다.

**prefetch() 메소드** : 모델이 훈련을 진행하는 동안 다음에 입력할 데이터를 불러와서 미리 전처리를 하도록 시스템을 조율하는 역할
- 병렬 처리를 통해서 모델 훈련 시간이 단축된다.

### **3. 모델 훈련 및 검증**

Sequential API로 생성  
배치 정규화, 합성곱, 풀링 레이어로 구성된 유닛 2개 ← 과대적합을 방지하는 요소들을 넣어서 모델을 구성한다.  
최종 분류기 : Dense 레이어 + Dropout  
> Dropout에 대한 정리는 [여기](https://yoooniverse.github.io/blog/%EB%AA%A8%EB%8D%B8%EC%84%B8%EB%B6%80%EC%84%A4%EC%A0%95/#43-%EB%93%9C%EB%A1%AD%EC%95%84%EC%9B%83dropout))

```python
def build_model():
    
    model = tf.keras.Sequential([
        #convolution 층
        tf.keras.layers.BatchNormalization(),
        tf.keras.layers.Conv2D(32, (3, 3), padding='same', activation='relu'),
        tf.keras.layers.MaxPooling2D((2, 2)),
        
        tf.keras.layers.BatchNormalization(),
        tf.keras.layers.Conv2D(64, (3, 3), padding='same', activation='relu'),
        tf.keras.layers.MaxPooling2D((2, 2)),
        
        #classifier 출력층
        tf.keras.layers.Flatten(),
        tf.keras.layers.Dense(128, activation='relu'),
        tf.keras.layers.Dropout(0.3),
        tf.keras.layers.Dense(64, activation='relu'),
        tf.keras.layers.Dropout(0.3),
        tf.keras.layers.Dense(NUM_CLASSES, activation='softmax'),
    ])
    
    return model

model = build_model()
```

그래프 그림을 통해 훈련 결과를 분석해보자.  

![](/assets/images/output1.png)

10 epoch까지는 손실함수가 급격하게 감소하는 양상을 확인 가능하다.
그 이후로는 손실함수가 더 감소하지 않고 과대적합 양상을 보이는 걸 알 수 있다.

### **4. 데이터 증강(Data Augmentation)**

모델을 훈련하기 위해 구성할 때 과대적합을 피하기 위한 장치들을 넣었음에도 과대적합이 발생했다.
데이터 증강 기법을 통해서도 과대적합을 해소하고, 모델의 robust한 성능을 확보할 수 있다.  
(robust : 인풋의 노이즈에 모델의 아웃풋이 흔들리지 않는 성능을 의미)

데이터 증강 기법의 기본 원리는, 이미지 데이터에 여러 변령을 주어서 훈련 데이터의 다양성을 확보하는 방식이다. (모델이 새로운 데이터에 대한 예측력을 강화하는 개념)

data augmentation 함수를 정의해서 데이터 증강 및 전처리를 수행하도록 한다.

- 이미지 증강 효과의 랜덤성 부여 : tf.image 모듈에서 지원하는 함수 중 random_으로 시작하는 함수들을 적용했다.
- map 함수로 원본 데이터셋에 정의한 함수를 적용해주고, 미니 배치로 만들어 준다.
 
```python
def data_augmentation(image, label):

    image=tf.image.random_flip_left_right(image)
    image=tf.image.random_flip_up_down(image)
    image=tf.image.random_brightness(image, max_delta=0.3)
    image=tf.image.random_crop(image, size=[64, 64, 3])
    
    image=tf.cast(image, tf.float32)/255. #0~1 정규화
    
    return image, label

train_aug = train_ds.map(data_augmentation, num_parallel_calls=tf.data.AUTOTUNE)
valid_aug = valid_ds.map(data_augmentation, num_parallel_calls=tf.data.AUTOTUNE)

train_aug = train_aug.shuffle(BUFFER_SIZE).batch(BATCH_SIZE).prefetch(tf.data.AUTOTUNE)
valid_aug = valid_aug.batch(BATCH_SIZE).cache().prefetch(tf.data.AUTOTUNE)

print(train_aug)
print(valid_aug)
```


![](/assets/images/output2.png)  


손실함수는 계속 줄어들고 정확도는 계속 증가하는 양상이다.
데이터 증강 기법을 적용한 결과 과대 적합 문제가 해소된 걸 확인할 수 있다.


### **5. ResNet 사전 학습 모델**
ResNet 모델을 활용해서 위성 이미지를 분류해보자.  
ResNet 모델이란 : 이미지넷 경진 대회에서 우승한 모델, 우수한 성능을 가진다. ← 이 모델을 그대로 가져와 위성이미지 분류 모델을 구성해 볼 것이다. 앞서 정리한 '전이 학습'의 개념이다.  
해당 딥러닝 모델의 구조와 가중치를 그대로 가져와서 모델의 top 레이어에 위성이미지 분류기를 추가하는 방식이다.

예제에서 사용한 ResNet 모델 버전은 'ResNet50V2' 버전이다.  
베이스 모델의 레이어 구조도 출력해서 살펴볼 수 있다.

```python
from tensorflow.keras.applications import ResNet50V2

pre_trained_base = ResNet50V2(include_top=False, weights='imagenet', input_shape=[64,64,3])
#중요) include_top 옵션을 false로 설정해서 top 레이어를 제거해준다.
#input_shape을 통해 위성 이미지의 크기를 입력해준다. 원래 모델의 입력 크기는 (224, 224, 3)으로 맞춰져 있다.

pre_trained_base.trainable = False
#중요) trainable을 false로 설정해서 모델의 가중치들이 훈련 과정에서 업데이트 되지 않도록 한다.

from tensorflow.python.keras.utils.vis_utils import plot_model
plot_model(pre_trained_base, show_shapes=True, show_layer_names=True, to_file='resnet50.png')
```

베이스 모델 위에 쌓을 탑 레이어의 구조이다.

```python
#Top 층에 Classifier 추가
def build_trainsfer_classifier():
    
    model = tf.keras.Sequential([
        
        pre_trained_base,
        
        tf.keras.layers.Flatten(),
        tf.keras.layers.Dense(128, activation='relu'),
        tf.keras.layers.Dropout(0.3),
        tf.keras.layers.Dense(64, activation='relu'),
        tf.keras.layers.Dropout(0.3),
        tf.keras.layers.Dense(NUM_CLASSES, activation='softmax'),
    ])
    
    return model

tc_model = build_trainsfer_classifier()
tc_model.summary()
```

![](/assets/images/output3.png)

데이터 증강 기법을 사용한 모델보다 더 빠르게 높은 정확도를 가지는 걸 볼 수 있다.
사전 학습 모델인 ResNet 모델의 가중치를 그대로 사용하기 때문에 새로운 데이터 위성 이미지를 넣어서 모델을 돌려도 이미지로부터 피처를 빠르게 추출할 수 있기 때문이다.

